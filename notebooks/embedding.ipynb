{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01eccd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from typing import List\n",
    "\n",
    "class TextChunker:\n",
    "    def __init__(self, chunk_size: int = 300, chunk_overlap: int = 50):\n",
    "        self.splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=chunk_size,\n",
    "            chunk_overlap=chunk_overlap\n",
    "        )\n",
    "\n",
    "    def chunk_texts(self, texts: List[str]) -> List[str]:\n",
    "        return self.splitter.split_texts(texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e9962a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from typing import List\n",
    "import numpy as np\n",
    "\n",
    "class Embedder:\n",
    "    def __init__(self, model_name: str = \"sentence-transformers/all-MiniLM-L6-v2\"):\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "\n",
    "    def embed_texts(self, texts: List[str]) -> np.ndarray:\n",
    "        return self.model.encode(texts, convert_to_numpy=True, show_progress_bar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38492c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "import pickle\n",
    "from typing import List, Dict\n",
    "\n",
    "class VectorStoreBuilder:\n",
    "    def __init__(self, dim: int):\n",
    "        self.index = faiss.IndexFlatL2(dim)\n",
    "        self.metadata = []\n",
    "\n",
    "    def add_embeddings(self, embeddings: np.ndarray, meta: List[Dict]):\n",
    "        self.index.add(embeddings)\n",
    "        self.metadata.extend(meta)\n",
    "\n",
    "    def save(self, index_path: str, metadata_path: str):\n",
    "        faiss.write_index(self.index, index_path)\n",
    "        with open(metadata_path, 'wb') as f:\n",
    "            pickle.dump(self.metadata, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91cb675",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load preprocessed data\n",
    "df = pd.read_csv(\"../data/processed/filtered_complaints.csv\")\n",
    "\n",
    "chunker = TextChunker(chunk_size=300, chunk_overlap=50)\n",
    "embedder = Embedder()\n",
    "vector_store = VectorStoreBuilder(dim=384)\n",
    "\n",
    "all_chunks = []\n",
    "all_metadata = []\n",
    "\n",
    "for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    chunks = chunker.chunk_texts([row['Consumer complaint narrative']])\n",
    "    meta = [{\n",
    "        \"product\": row[\"Product_Mapped\"],\n",
    "        \"complaint_id\": row[\"Complaint ID\"],\n",
    "        \"original_text\": chunk\n",
    "    } for chunk in chunks]\n",
    "\n",
    "    all_chunks.extend(chunks)\n",
    "    all_metadata.extend(meta)\n",
    "\n",
    "# Embed all chunks at once\n",
    "embeddings = embedder.embed_texts(all_chunks)\n",
    "\n",
    "# Store vectors and metadata\n",
    "vector_store.add_embeddings(embeddings, all_metadata)\n",
    "vector_store.save(\"../vector_store/index.faiss\", \"../vector_store/metadata.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
